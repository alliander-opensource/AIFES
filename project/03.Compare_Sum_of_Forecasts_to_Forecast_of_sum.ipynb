{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23840817",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import cufflinks\n",
    "cufflinks.go_offline()\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from datetime import datetime\n",
    "import os\n",
    "import yaml\n",
    "\n",
    "from openstef.pipeline.train_create_forecast_backtest import train_model_and_forecast_back_test\n",
    "from openstef.metrics.figure import plot_feature_importance\n",
    "from openstef.data_classes.model_specifications import ModelSpecificationDataClass\n",
    "from openstef.data_classes.prediction_job import PredictionJobDataClass\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b317e3dc",
   "metadata": {},
   "source": [
    "# Sum of forecasts or forecast the sum?\n",
    "Decisions are seldom based on forecasts for single sensors. Therefore combining either sensor data or the forecasts of these timeseries is nescesarry to obtain forecasts for the quantitiy of interest. Various strategies can be employed to achieve this with each of them having advantages and disadvantages. Here, we compare two of these strategies: 1) Take the sum of the sensors and forecast this sum and 2) Forecast each sensor individually and sum the resulting forecasts. \n",
    "\n",
    "For two differen substations, Middenmeer and Oosterwolde, we make forecasts for each individual sensor and the sum of the sensors with the openSTEF backtest pipeline. Because of the stochastic nature of the backtest we repeat it 10 times to aquire some statistics. We compare the resulting forecasts in terms of MAE, rMAE and rMAE for the lowest 5% of the values.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5b3c507",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data Middenmeer\n",
    "filename = Path(\"./input/Middenmeer-150kV.csv\")\n",
    "\n",
    "data_wop = pd.read_csv(filename, delimiter=\";\", decimal=\",\")\n",
    "data_wop[\"Datetime\"] = pd.to_datetime(data_wop[\"Datum\"] + \" \" + data_wop[\"Tijd\"])\n",
    "data_wop = data_wop.set_index('Datetime').tz_localize('CET', ambiguous='NaT', nonexistent='NaT').tz_convert(\"UTC\")\n",
    "\n",
    "data_150_kv = data_wop.iloc[:, 2:-1]\n",
    "\n",
    "data_150_kv[\"Sum\"] = data_150_kv.sum(axis=1)\n",
    "\n",
    "# Load data Oostterwolde\n",
    "filename = Path(\"./input/Oosterwolde-10kV.csv\")\n",
    "data_wop = pd.read_csv(filename, delimiter=\";\", decimal=\",\")\n",
    "data_wop[\"Datetime\"] = pd.to_datetime(data_wop[\" Datum\"] + \" \" + data_wop[\"Tijd\"])\n",
    "data_wop = data_wop.set_index('Datetime').tz_localize('CET', ambiguous='NaT', nonexistent='NaT').tz_convert(\"UTC\")\n",
    "\n",
    "data_20_kv_oosterwolde = data_wop.iloc[:, 2:-1]\n",
    "data_20_kv_oosterwolde[\"Sum\"] = data_20_kv_oosterwolde.sum(axis=1)\n",
    "\n",
    "data_20_kv_oosterwolde = data_20_kv_oosterwolde * -1\n",
    "# Load predictors\n",
    "predictors = pd.read_csv('./input/predictors.csv', index_col=0, parse_dates=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d52e3ae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.matshow(data_150_kv.corr())\n",
    "cb = plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54e80d25",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_150_kv.iplot(xTitle=\"Datetime\", yTitle=\"Power [MW]\", title=\"Middenmeer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70c13e06",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.matshow(data_20_kv_oosterwolde.corr())\n",
    "cb = plt.colorbar()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31f275b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_20_kv_oosterwolde.iplot(xTitle=\"Datetime\", yTitle=\"Power [MW]\", title=\"Oosterwolde\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdfee586",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run backtest 10 times to obtain enough samples\n",
    "overal_results = {}\n",
    "for sample in range(10):\n",
    "    results = {}\n",
    "    for target_column in data_20_kv_oosterwolde.columns:\n",
    "        # Define properties of training/prediction. We call this a 'prediction_job' \n",
    "        pj=PredictionJobDataClass(\n",
    "            id=1,\n",
    "            name='TestPrediction',\n",
    "            model='xgb',\n",
    "            quantiles=[0.10,0.30,0.50,0.70,0.90],\n",
    "            horizon_minutes=24*60,\n",
    "            resolution_minutes=15,\n",
    "\n",
    "            forecast_type=\"demand\", # Note, this should become optional\n",
    "            lat = 1, #should become optional\n",
    "            lon = 1, #should become optional\n",
    "                          )\n",
    "\n",
    "        training_horizons=[0.25, 47.0, 24.0]\n",
    "\n",
    "        # Make backtest using a single model for all lead times\n",
    "        # Define backtest specs\n",
    "        backtest_specs = dict(n_folds=3, training_horizons=training_horizons)\n",
    "        modelspecs = ModelSpecificationDataClass(id=pj['id'])\n",
    "\n",
    "        # Specify input data, use last column of the load dataframe\n",
    "        input_data = pd.DataFrame(dict(load=data_20_kv_oosterwolde.loc[:,target_column])).merge(predictors, left_index=True, right_index=True)\n",
    "        # Also resample to fix overlapping indices\n",
    "        input_data = input_data.resample('15T').mean()\n",
    "\n",
    "\n",
    "        # Perform the backtest\n",
    "        forecast_single_model, model_single_model, train_data, validation_data, test_data = train_model_and_forecast_back_test(\n",
    "            pj,\n",
    "            modelspecs = modelspecs,\n",
    "            input_data = input_data,\n",
    "            **backtest_specs,\n",
    "         )\n",
    "\n",
    "        # Store the model, so it can be compared to the other models\n",
    "        models=dict(multihorizonmodel=model_single_model)\n",
    "\n",
    "        results[target_column] = forecast_single_model\n",
    "\n",
    "    sum_forecast = []\n",
    "    for key in results.keys():\n",
    "        if key!=\"Sum\":\n",
    "            sum_forecast.append(results[key][results[key][\"horizon\"]==24.00][\"forecast\"].rename(key))\n",
    "\n",
    "    res = sum_forecast[0]\n",
    "    for col in sum_forecast[1:]:    \n",
    "        res += col.fillna(0)\n",
    "    res = res.rename(\"Sum_Forecast\").to_frame()\n",
    "    res[\"Realised\"] = results[\"Sum\"][results[\"Sum\"][\"horizon\"]==24.00][\"realised\"]\n",
    "    res[\"Forecast_Sum\"] = results[\"Sum\"][results[\"Sum\"][\"horizon\"]==24.00][\"forecast\"]\n",
    "    res.to_csv(f\"results_trial_{sample}.csv\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c922362a",
   "metadata": {},
   "source": [
    "# Results & Conclusion\n",
    "For Oosterwolde we see a clear improvement of forecast quality when forecasting the sum instead of summing the individual forecasts in terms of the overal relative mean absolute error. This is not strange as the forecast of the sum takes advantage of averaging and strange fluctuations in the individual sensor traces are small when compared to the total.\n",
    "\n",
    "When we look at the results for Middenmeer this effect is suprisingly not visible. The forecast quality of both strategies is roughly the same or slightly better for the sum of the individual forecasts. To find the exact cause of this we need to compare data from more substations. Another idea is to repeat this exercise fro forecasts of individual customers. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5d85120",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Compare results\n",
    "import openstef.metrics.metrics as metrics\n",
    "\n",
    "for substation in [\"middenmeer\", \"oostterwolde\"]:\n",
    "    list_res = []\n",
    "    overal_results = {}\n",
    "    for sample in range(10):\n",
    "        res_metrics = {}\n",
    "        res = pd.read_csv(f\"./{substation}/results_trial_{sample}.csv\", parse_dates=True, index_col=0)\n",
    "        res_metrics[\"Sum_Forecast\"]= [metrics.r_mae_lowest(res[\"Realised\"],res[\"Sum_Forecast\"]),metrics.r_mae(res[\"Realised\"],res[\"Sum_Forecast\"])]\n",
    "        res_metrics[\"Forecast_Sum\"]= [metrics.r_mae_lowest(res[\"Realised\"],res[\"Forecast_Sum\"]),metrics.r_mae(res[\"Realised\"],res[\"Forecast_Sum\"])]\n",
    "\n",
    "        res_metrics_df = pd.DataFrame.from_dict(res_metrics)\n",
    "        res_metrics_df.index = [\"rMAE_lowest\", \"rMAE\"]\n",
    "\n",
    "        overal_results[sample] = res_metrics_df\n",
    "\n",
    "\n",
    "\n",
    "        list_res.append(overal_results[sample])\n",
    "\n",
    "    results = pd.concat(list_res).reset_index()\n",
    "    \n",
    "    results[results[\"index\"]==\"rMAE\"][[\"Sum_Forecast\", \"Forecast_Sum\"]].iplot(title=substation, kind=\"box\",  yTitle=\"rMAE\")\n",
    "    \n",
    "    results[results[\"index\"]==\"rMAE_lowest\"][[\"Sum_Forecast\", \"Forecast_Sum\"]].iplot(kind=\"box\",title=substation,  yTitle=\"rMAE_lowest\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22b53c63",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
