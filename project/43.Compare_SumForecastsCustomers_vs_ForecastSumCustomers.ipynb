{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b1606c69",
   "metadata": {},
   "source": [
    "This notebook is the result of issue [#43](https://github.com/alliander-opensource/AIFES/issues/43)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f8b37b6",
   "metadata": {},
   "source": [
    "# Sum of forecasts or forecast the sum?\n",
    "Decisions are seldom based on forecasts for single sensors. Therefore combining either sensor data or the forecasts of these timeseries is nescesarry to obtain forecasts for the quantitiy of interest. Various strategies can be employed to achieve this with each of them having advantages and disadvantages. \n",
    "\n",
    "Here, we compare these strategies to forecast the total load on a substation: \n",
    "1) Forecast the total load directly.\n",
    "2) Forecast and combine:\n",
    "   1) Total load large customers\n",
    "   2) Residual load substation\n",
    "3) Forecast and combine\n",
    "   1) Individual load large customers\n",
    "   2) Residual load substation\n",
    "\n",
    "We are going to run this comparison for Westwoud, since there the customer population is most diverse. To generate forecasts, we use the openSTEF backtest pipeline. Because of the stochastic nature of the backtest we repeat it 10 times to aquire some statistics. We compare the resulting forecasts in terms of MAE, rMAE and rMAE for the lowest 5% of the values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1dc7342",
   "metadata": {},
   "source": [
    "# Imports and data preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b0927d1",
   "metadata": {},
   "source": [
    "## Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3743c46",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7a0b969",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "import os\n",
    "\n",
    "from openstef.pipeline.train_create_forecast_backtest import train_model_and_forecast_back_test\n",
    "from openstef.metrics.figure import plot_feature_importance\n",
    "from openstef.data_classes.model_specifications import ModelSpecificationDataClass\n",
    "from openstef.data_classes.prediction_job import PredictionJobDataClass\n",
    "\n",
    "# Set working dir to location of this file\n",
    "os.chdir('.')\n",
    "\n",
    "# Set plotly as the default pandas plotting backend\n",
    "pd.options.plotting.backend = 'plotly'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1088d2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.io as pio\n",
    "\n",
    "# This ensures Plotly output works in multiple places:\n",
    "# plotly_mimetype: VS Code notebook UI\n",
    "# notebook: \"Jupyter: Export to HTML\" command in VS Code\n",
    "# See https://plotly.com/python/renderers/#multiple-renderers\n",
    "pio.renderers.default = \"plotly_mimetype+notebook\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b7086e9",
   "metadata": {},
   "source": [
    "## EMS measurements\n",
    "Load, pre-process, and visualize "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "093517c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load inputs\n",
    "filename = Path(\"../.data/Westwoud-50_10kV.csv\")\n",
    "\n",
    "measurements = pd.read_csv(filename, delimiter=\";\", decimal=\",\")\n",
    "measurements[\"Datetime\"] = pd.to_datetime(measurements.iloc[:,0] + \" \" + measurements.iloc[:,1])\n",
    "measurements = measurements.set_index('Datetime').tz_localize('CET', ambiguous='NaT', nonexistent='NaT').tz_convert(\"UTC\")\n",
    "\n",
    "# Only keep relevant columns\n",
    "measurements = measurements.iloc[:,2:-1]\n",
    "\n",
    "# Sum the load\n",
    "measurements['Total'] = measurements.sum(axis=1)\n",
    "\n",
    "# By default, only a backtest is made for the total\n",
    "target_column = 'Total'\n",
    "\n",
    "# Drop all rows with a NaT index.\n",
    "measurements = measurements[measurements.index.notna()]\n",
    "\n",
    "# remove dupicates\n",
    "measurements = measurements[~measurements.index.duplicated()]\n",
    "\n",
    "# Resample per 15 minutes\n",
    "measurements = measurements.resample('15T').mean()\n",
    "\n",
    "# Polarity of measurements is inverted\n",
    "measurements *= -1\n",
    "\n",
    "measurements.iloc[1000:2000,:].plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6134e3b9",
   "metadata": {},
   "source": [
    "### Check the validity of the measurements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19b422f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validate that there are no duplicates left\n",
    "assert not(measurements.index.duplicated().any()), \"Duplicate indices have been found in the measurements dataframe.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc186870",
   "metadata": {},
   "source": [
    "## Measurements large customers (C-ARM data)\n",
    "Load, pre-process, and visualize  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b215cdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "large_clients = pd.read_csv(\"../.data/westwoud_clients.csv\", index_col=0)\n",
    "\n",
    "carm_measurements = pd.read_csv(\"../.data/wew_customer_carm_measurements.csv\", \n",
    "                                delimiter=\",\", decimal=\".\", index_col=0, parse_dates=True)\n",
    "carm_measurements /= 1E6 # rescale from -W to to MW"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a9af1e9",
   "metadata": {},
   "source": [
    "## Let's inspect the measurements of large customers and determine their contribution to the total load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76e96f39",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "carm_measurements.aggregate([max, np.median, min]).T.plot(kind='box')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5df5c85",
   "metadata": {},
   "outputs": [],
   "source": [
    "carm_measurements['Total'] = carm_measurements.sum(axis=1)\n",
    "carm_measurements.iloc[20000:21000].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0756ce05",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_customer_load = carm_measurements['Total']\n",
    "residual_load = pd.DataFrame(dict(load=measurements[target_column] - total_customer_load))\n",
    "# for sanity, plot the total, customer and residual load\n",
    "loads = measurements[[target_column]].merge(pd.DataFrame(residual_load), left_index=True, right_index=True, how='outer').merge(pd.DataFrame(total_customer_load), left_index=True, right_index=True, how='outer')\n",
    "loads.columns=['Realized','Residual','Customer_Total']\n",
    "\n",
    "loads.iloc[1000:2000,:].plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62fb0e11",
   "metadata": {},
   "source": [
    "## Change of plans\n",
    "We find large differences between the total load, and the Customer_total. Let's change our original plan and asses:\n",
    "Investigate difference in accuracy:\n",
    "- Forecast `customer_total` directly\n",
    "- Forecast each customer seperately"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48cf55c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find largest customers:\n",
    "largest_customers = carm_measurements.abs().max(axis=0).sort_values(ascending=False)[:6]\n",
    "carm_measurements.loc[:,largest_customers.index].iloc[21000:22000].plot()\n",
    "# Looks like 1 windpark, 2 solar parks, and 2 large consumers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e76bfe37",
   "metadata": {},
   "source": [
    "The Figure shows the timeseries of the Total customer load, and the 5 largest customers. These include a windpark, two solar parks and two large consumers. The windpark and one of the solar parks are an order of magnitude larger than the next largest customers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0e85d65",
   "metadata": {},
   "source": [
    "## Predictors\n",
    "Load, pre-process, and visualize "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf07a141",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load predictors\n",
    "predictors = pd.read_csv('../.data/weather_apx_sji_sja_Middenmeer.csv', index_col=0, parse_dates=True)\n",
    "predictors.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37b98bb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the validity of the predictors data\n",
    "assert not(predictors.duplicated().any()), \"Duplicate values have been found in the predictors dataframe.\"\n",
    "assert not(predictors.index.duplicated().any()), \"Duplicate indices have been found in the predictors dataframe.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df5c4490",
   "metadata": {},
   "source": [
    "# Backtests"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cb85e65",
   "metadata": {},
   "source": [
    "#### Configure training, prediction, and backtest specifications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98139d87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define properties of training / prediction. We call this a 'prediction_job'.\n",
    "pj=PredictionJobDataClass(\n",
    "    id=1, # Does not matter in a backtest context\n",
    "    name='TestPrediction', # Does not matter in a backtest context\n",
    "    model='xgb',\n",
    "    quantiles=[0.5], # We will only consider the P50 forecast\n",
    "    horizon_minutes=24*60,\n",
    "    resolution_minutes=15,\n",
    "    forecast_type=\"demand\", # Note, this should become optional\n",
    "    lat = 1, # should become optional\n",
    "    lon = 1, # should become optional\n",
    ")\n",
    "\n",
    "# The modelspecs do not do much if only an \"id\" is specified.\n",
    "modelspecs = ModelSpecificationDataClass(id=pj['id'])\n",
    "\n",
    "# Define backtest specs.\n",
    "backtest_specs = dict(n_folds=3, \n",
    "                      # The training horizon also decides for which forecast horizon, backtest forecasts are made.\n",
    "                      training_horizons=[24.0]) # We will only consider a single training horizon"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c79a8b4c",
   "metadata": {},
   "source": [
    "## Forecast Total Customers Directly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dede7b49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OpenSTEF always expects a column called \"load\". This is the column it will predict.\n",
    "load = pd.DataFrame(dict(load=carm_measurements['Total']))\n",
    "input_data = load.merge(predictors, left_index=True, right_index=True, how='inner')\n",
    "\n",
    "assert not(input_data.index.duplicated().any()), \"There are duplicate indices in the input data.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7da2cdbd",
   "metadata": {},
   "source": [
    "#### Perform and save the results of the backtest `n_iterations` times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9b2328c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.persisting_artifacts import write_artifacts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e23d3edf",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_iterations = 1 #set to a small number while developing, set to 10 for the Champion Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b61e8eb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(n_iterations):\n",
    "    # Perform the backtest\n",
    "    forecast, models, train_data, validation_data, test_data = train_model_and_forecast_back_test(\n",
    "        pj,\n",
    "        modelspecs = modelspecs,\n",
    "        input_data = input_data,\n",
    "        **backtest_specs,\n",
    "    )\n",
    "    \n",
    "    # If n_folds > 1, models is a list of models. In that case, only use the first model.\n",
    "    if backtest_specs['n_folds'] > 1:\n",
    "        model=models[0]\n",
    "    else:\n",
    "        model=models\n",
    "\n",
    "    run_name = f\"{datetime.utcnow():%Y%m%d}_WEW_top_down_sample_{i}\"\n",
    "    write_artifacts(run_name, forecast, model, pj, backtest_specs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a33dd00f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option(\"display.max_columns\", 130)\n",
    "train_data[0].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d262a1b3",
   "metadata": {},
   "source": [
    "## Each customer seperately"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79fd5778",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "import openstef.metrics.metrics as metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9905f217",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run backtest\n",
    "# Calculate results immediately.\n",
    "combined_forecast = pd.DataFrame(columns=['forecast', 'realised'])\n",
    "res_metrics=pd.DataFrame(columns=['rmae_lowest', 'rmae', 'rmae_highest', 'rmse', 'mae'])\n",
    "for customer in tqdm(carm_measurements.columns):\n",
    "    if customer == 'Total':\n",
    "        continue\n",
    "    input_data = pd.DataFrame(dict(load=carm_measurements[customer])).merge(predictors, left_index=True, right_index=True, how='inner')\n",
    "    # Perform the backtest\n",
    "    forecast, models, train_data, validation_data, test_data = train_model_and_forecast_back_test(\n",
    "        pj,\n",
    "        modelspecs = modelspecs,\n",
    "        input_data = input_data,\n",
    "        **backtest_specs,\n",
    "    )\n",
    "    \n",
    "    # If n_folds > 1, models is a list of models. In that case, only use the first model.\n",
    "    if backtest_specs['n_folds'] > 1:\n",
    "        model=models[0]\n",
    "    else:\n",
    "        model=models\n",
    "        \n",
    "    # Check if actually a forecast was made\n",
    "    if forecast[\"forecast\"].isna().sum()<10:\n",
    "        print('No forecast was made. Perhaps the load was constant (0) or missing?')\n",
    "        continue\n",
    "        \n",
    "    # Calculate KPI\n",
    "    res_metrics.loc[customer, :] = [\n",
    "        metrics.r_mae_lowest(forecast[\"realised\"], forecast[\"forecast\"]),\n",
    "        metrics.r_mae(forecast[\"realised\"], forecast[\"forecast\"]),\n",
    "        metrics.r_mae_highest(forecast[\"realised\"], forecast[\"forecast\"]),\n",
    "        metrics.rmse(forecast[\"realised\"], forecast[\"forecast\"]),\n",
    "        metrics.mae(forecast[\"realised\"], forecast[\"forecast\"]),\n",
    "                            ]\n",
    "    \n",
    "    if len(combined_forecast) == 0:\n",
    "        combined_forecast = forecast[['forecast','realised']]\n",
    "    else:\n",
    "        combined_forecast['forecast'] += forecast['forecast']\n",
    "        combined_forecast['realised'] += forecast['realised']\n",
    "\n",
    "    run_name = f\"{datetime.utcnow():%Y%m%d}_WEW_customer_{customer}\"\n",
    "    write_artifacts(run_name, forecast, model, pj, backtest_specs)\n",
    "\n",
    "    \n",
    "combined_forecast.to_csv(f\"output/{datetime.utcnow():%Y%m%d}_WEW_total_customers.csv\")\n",
    "res_metrics.to_csv(f\"output/{datetime.utcnow():%Y%m%d}_WEW_total_customers_metrics.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8f07f68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load from history - useful for when exporting the notebook went wrong and you don't want to redo the entire backtests\n",
    "combined_forecast = pd.read_csv('output/20230731_WEW_total_customers.csv', index_col=0, parse_dates=True)\n",
    "res_metrics = pd.read_csv('output/20230731_WEW_total_customers_metrics.csv', index_col=0, parse_dates=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3844dff7",
   "metadata": {},
   "source": [
    "## Evaluate results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca79370b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve the forecasts from the stored files\n",
    "import glob\n",
    "relevant_files = glob.glob('output/20230731_WEW_customer_*/forecast.csv')\n",
    "sum_forecast = pd.DataFrame()\n",
    "sum_realised = pd.DataFrame()\n",
    "for file in tqdm(relevant_files):\n",
    "    fc = pd.read_csv(file, index_col=0, parse_dates=True, compression='gzip')\n",
    "\n",
    "    if len(sum_forecast)==0:\n",
    "        sum_forecast=fc[['forecast']]\n",
    "        sum_realised=fc[['realised']]\n",
    "        continue\n",
    "\n",
    "    sum_forecast = pd.DataFrame(sum_forecast).merge(fc.forecast, left_index=True, right_index=True, how='outer').sum(axis=1)\n",
    "    sum_realised = pd.DataFrame(sum_realised).merge(fc.realised, left_index=True, right_index=True, how='outer').sum(axis=1)\n",
    "                              \n",
    "    if sum_forecast.isna().sum()>1000:\n",
    "        print('NAN!!')\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f551b39",
   "metadata": {},
   "outputs": [],
   "source": [
    "aggregate = pd.DataFrame(data=dict(forecast=sum_forecast, realised=sum_realised))\n",
    "res_metrics.loc['Aggregate',:] = [\n",
    "        metrics.r_mae_lowest(aggregate[\"realised\"], aggregate[\"forecast\"]),\n",
    "        metrics.r_mae(aggregate[\"realised\"], aggregate[\"forecast\"]),\n",
    "        metrics.r_mae_highest(aggregate[\"realised\"], aggregate[\"forecast\"]),\n",
    "        metrics.rmse(aggregate[\"realised\"], aggregate[\"forecast\"]),\n",
    "        metrics.mae(aggregate[\"realised\"], aggregate[\"forecast\"]),\n",
    "                            ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2fa0b02",
   "metadata": {},
   "outputs": [],
   "source": [
    "direct_forecast = pd.read_csv('output/20230731_WEW_top_down_sample_0/forecast.csv', compression='gzip', index_col=0, parse_dates=True)\n",
    "\n",
    "res_metrics.loc['Direct', :] = [\n",
    "        metrics.r_mae_lowest(direct_forecast[\"realised\"], direct_forecast[\"forecast\"]),\n",
    "        metrics.r_mae(direct_forecast[\"realised\"], direct_forecast[\"forecast\"]),\n",
    "        metrics.r_mae_highest(direct_forecast[\"realised\"], direct_forecast[\"forecast\"]),\n",
    "        metrics.rmse(direct_forecast[\"realised\"], direct_forecast[\"forecast\"]),\n",
    "        metrics.mae(direct_forecast[\"realised\"], direct_forecast[\"forecast\"]),\n",
    "                            ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0177ae82",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = res_metrics.loc[['Direct','Aggregate'],'mae'].plot(kind='bar', width=600)\n",
    "fig.update_layout(dict(yaxis=dict(title='MAE [MW]'), xaxis=dict(title=''), showlegend=False), title='Forecasting the total customer load directly <br>versus <br>aggregating the forecasts for each individual customer',\n",
    "                  margin=dict(t=100, b=0, l=0, r=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec46d8c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate MAE of largest customers\n",
    "res_metrics['shortname'] = [x if len(x)<10 else f'{x[:8]}..' for x in res_metrics.index ]\n",
    "fig = res_metrics.sort_values(by='mae', ascending=False)[:10].plot(y='mae', x='shortname', width=600, kind='bar')\n",
    "fig.update_layout(dict(yaxis=dict(title='MAE [MW]'), xaxis=dict(title='')))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c4600d5",
   "metadata": {},
   "source": [
    "The MAE of forecasting the direct load is larger than the MAE of the aggregate of the forecasts of the individual customers. \n",
    "\n",
    "This analysis should be repeated to claim statistical significance. However, it can be seen that forecasting the individual customers seperately at least does not increase the forecasting error. \n",
    "\n",
    "Moreover, the two customers with the largest MAE are the large wind and solar park, as depicted in a previous figure. \n",
    "\n",
    "From a machine learning point of view, it can be understood that forecasting the loads of a solar and windpark seperately, allows machine learning models to learn a more straightforward relation compared to forecasting the aggregate of that. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77fcfb41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's compare the direct and aggregated forecasts and realised\n",
    "combined = direct_forecast[['forecast','realised']].rename(columns=dict(forecast='forecast_direct', realised='realised_direct'))\n",
    "combined = combined.merge(aggregate.rename(columns=dict(forecast='forecast_aggregate', realised='realised_aggregate')), left_index=True, right_index=True, how='outer')\n",
    "fig = combined.plot()\n",
    "fig.update_layout(yaxis=dict(title='Power [MW]'), xaxis=dict(title=''))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce987130",
   "metadata": {},
   "source": [
    "Figure shows the timeseries of the direct and aggregated forecast, as well as the realization. As a sanity check, the individual realizations of all customers from the backtest dataframes are aggregated to show it matches the original `total_customers`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25042869",
   "metadata": {},
   "source": [
    "# Export notebook as html\n",
    "Write this notebook to html."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f731c300",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "nb_fname = '43.Compare_SumForecastsCustomers_vs_ForecastSumCustomers'\n",
    "command=f\"jupyter nbconvert {nb_fname}.ipynb --to html --no-input --output results/{nb_fname}.html\"\n",
    "print(f\"Command to be executed: {command}.\")\n",
    "os.system(command)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4a7a7a6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
