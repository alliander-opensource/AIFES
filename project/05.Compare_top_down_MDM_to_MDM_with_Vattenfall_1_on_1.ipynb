{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e1dc7342",
   "metadata": {},
   "source": [
    "# Imports and data preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b0927d1",
   "metadata": {},
   "source": [
    "## Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3743c46",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7a0b969",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "import os\n",
    "\n",
    "from openstef.pipeline.train_create_forecast_backtest import train_model_and_forecast_back_test\n",
    "from openstef.metrics.figure import plot_feature_importance\n",
    "from openstef.data_classes.model_specifications import ModelSpecificationDataClass\n",
    "from openstef.data_classes.prediction_job import PredictionJobDataClass\n",
    "\n",
    "# Set working dir to location of this file\n",
    "os.chdir('.')\n",
    "\n",
    "# Set plotly as the default pandas plotting backend\n",
    "pd.options.plotting.backend = 'plotly'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1088d2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.io as pio\n",
    "\n",
    "# This ensures Plotly output works in multiple places:\n",
    "# plotly_mimetype: VS Code notebook UI\n",
    "# notebook: \"Jupyter: Export to HTML\" command in VS Code\n",
    "# See https://plotly.com/python/renderers/#multiple-renderers\n",
    "pio.renderers.default = \"plotly_mimetype+notebook\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b7086e9",
   "metadata": {},
   "source": [
    "## EMS measurements\n",
    "Load, pre-process, and visualize "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "093517c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load inputs\n",
    "filename = Path(\"../.data/Middenmeer-150kV.csv\")\n",
    "\n",
    "measurements = pd.read_csv(filename, delimiter=\";\", decimal=\",\")\n",
    "measurements[\"Datetime\"] = pd.to_datetime(measurements[\"Datum\"] + \" \" + measurements[\"Tijd\"])\n",
    "measurements = measurements.set_index('Datetime').tz_localize('CET', ambiguous='NaT', nonexistent='NaT').tz_convert(\"UTC\")\n",
    "\n",
    "# Only keep relevant columns\n",
    "measurements = measurements.iloc[:,2:-1]\n",
    "\n",
    "# Sum the load\n",
    "measurements['Total'] = measurements.sum(axis=1)\n",
    "\n",
    "# By default, only a backtest is made for the total\n",
    "target_column = 'Total'\n",
    "\n",
    "measurements.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6134e3b9",
   "metadata": {},
   "source": [
    "### Check the validity of the measurements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5897ed49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show all rows with a duplicate index\n",
    "measurements[measurements.index.duplicated(keep=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38fae638",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop all rows with a NaT index.\n",
    "measurements = measurements[measurements.index.notna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19b422f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validate that there are no duplicates left\n",
    "assert not(measurements.index.duplicated().any()), \"Duplicate indices have been found in the measurements dataframe.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc186870",
   "metadata": {},
   "source": [
    "## C-ARM & T-prognoses Vattenfall\n",
    "Load, pre-process, and visualize  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b215cdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "large_clients = pd.read_csv(\"../.data/middenmeer_clients.csv\", index_col=0)\n",
    "vattenfall_mrids = large_clients.query(\"'Vattenfall Windpark Wieringermeer B.V.' in Name\")[\"mRID\"]\n",
    "\n",
    "carm_measurements = pd.read_csv(\"../.data/mdm_customer_carm_measurements.csv\", \n",
    "                                delimiter=\",\", decimal=\".\", index_col=0, parse_dates=True)\n",
    "customer_power_forecast = pd.read_csv(\"../.data/mdm_customer_power_forecasts_2022.csv\", \n",
    "                             delimiter=\",\", decimal=\".\", index_col=0, parse_dates=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22dbd16f",
   "metadata": {},
   "outputs": [],
   "source": [
    "vattenfall_carm_measurements = carm_measurements[vattenfall_mrids]\n",
    "vattenfall_power_forecasts = customer_power_forecast[vattenfall_mrids]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47c072bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "aggregated_vattenfall_load_watt = vattenfall_carm_measurements.sum(axis=1)\n",
    "aggregated_vattenfall_power_forecasts_watt = vattenfall_power_forecasts.sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3138712",
   "metadata": {},
   "outputs": [],
   "source": [
    "aggregated_vattenfall_load = aggregated_vattenfall_load_watt / 1000000\n",
    "aggregated_vattenfall_power_forecasts = aggregated_vattenfall_power_forecasts_watt / 1000000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0e85d65",
   "metadata": {},
   "source": [
    "## Predictors\n",
    "Load, pre-process, and visualize "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf07a141",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load predictors\n",
    "predictors = pd.read_csv('../.data/weather_apx_sji_sja_Middenmeer.csv', index_col=0, parse_dates=True)\n",
    "predictors.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37b98bb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the validity of the predictors data\n",
    "assert not(predictors.duplicated().any()), \"Duplicate values have been found in the predictors dataframe.\"\n",
    "assert not(predictors.index.duplicated().any()), \"Duplicate indices have been found in the predictors dataframe.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df5c4490",
   "metadata": {},
   "source": [
    "# Backtests"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c79a8b4c",
   "metadata": {},
   "source": [
    "## Top down Middenmeer forecasts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24be8bf2",
   "metadata": {},
   "source": [
    "### Combine EMS measurements and predictors to get input data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dede7b49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OpenSTEF always expects a column called \"load\". This is the column it will predict.\n",
    "load = pd.DataFrame(dict(load=measurements.loc[:,target_column]))\n",
    "input_data = load.merge(predictors, left_index=True, right_index=True, how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eb7664a",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert not(input_data.index.duplicated().any()), \"There are duplicate indices in the input data.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ae08bf4",
   "metadata": {},
   "source": [
    "### Backtest configuration and execution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cb85e65",
   "metadata": {},
   "source": [
    "#### Configure training, prediction, and backtest specifications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98139d87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define properties of training / prediction. We call this a 'prediction_job'.\n",
    "pj=PredictionJobDataClass(\n",
    "    id=1, # Does not matter in a backtest context\n",
    "    name='TestPrediction', # Does not matter in a backtest context\n",
    "    model='xgb',\n",
    "    quantiles=[0.10, 0.4, 0.50, 0.70, 0.90],\n",
    "    horizon_minutes=24*60, # TODO: Find out: Does this influence anything? Does this influence which lagged features are available at prediction time?\n",
    "    resolution_minutes=15,\n",
    "    forecast_type=\"demand\", # Note, this should become optional\n",
    "    lat = 1, # should become optional\n",
    "    lon = 1, # should become optional\n",
    "    # train_components=False, #should become optional\n",
    "    # model_type_group=None, # Note, this should become optional\n",
    "    # hyper_params={}, # Note, this should become optional\n",
    "    # feature_names=None, # Note, this should become optional\n",
    ")\n",
    "\n",
    "# The modelspecs do not do much if only an \"id\" is specified.\n",
    "modelspecs = ModelSpecificationDataClass(id=pj['id'])\n",
    "\n",
    "# Define backtest specs.\n",
    "backtest_specs = dict(n_folds=3, \n",
    "                      # The training horizon also decides for which forecast horizon, backtest forecasts are made.\n",
    "                      training_horizons=[0.25, 47.0, 24.0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7da2cdbd",
   "metadata": {},
   "source": [
    "#### Perform and save the results of the backtest 10 times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9b2328c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.persisting_artifacts import write_artifacts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b61e8eb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    # Perform the backtest\n",
    "    forecast, models, train_data, validation_data, test_data = train_model_and_forecast_back_test(\n",
    "        pj,\n",
    "        modelspecs = modelspecs,\n",
    "        input_data = input_data,\n",
    "        **backtest_specs,\n",
    "    )\n",
    "    \n",
    "    # If n_folds > 1, models is a list of models. In that case, only use the first model.\n",
    "    if backtest_specs['n_folds'] > 1:\n",
    "        model=models[0]\n",
    "    else:\n",
    "        model=models\n",
    "\n",
    "    run_name = f\"{datetime.utcnow():%Y%m%d}_MDM_top_down_sample_{i}\"\n",
    "    write_artifacts(run_name, forecast, model, pj, backtest_specs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a33dd00f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option(\"display.max_columns\", 130)\n",
    "train_data[0].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d262a1b3",
   "metadata": {},
   "source": [
    "## Middenmeer forecasts with Vattenfall power forecasts 1 on 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e94a587b",
   "metadata": {},
   "source": [
    "### Combine EMS measurements, Vattenfall C-ARM data, and predictors to get input data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40040d76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OpenSTEF always expects a column called \"load\". This is the column it will predict.\n",
    "load = pd.DataFrame(dict(load=measurements[target_column] - aggregated_vattenfall_load))\n",
    "input_data = load.merge(predictors, left_index=True, right_index=True, how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b2b17b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert not(input_data.index.duplicated().any()), \"There are duplicate indices in the input data.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "169bd2e5",
   "metadata": {},
   "source": [
    "### Backtest configuration and execution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebabe4eb",
   "metadata": {},
   "source": [
    "#### Configure training, prediction, and backtest specifications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d3dd3fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define properties of training / prediction. We call this a 'prediction_job'.\n",
    "pj=PredictionJobDataClass(\n",
    "    id=1, # Does not matter in a backtest context\n",
    "    name='TestPrediction', # Does not matter in a backtest context\n",
    "    model='xgb',\n",
    "    quantiles=[0.10,0.30,0.50,0.70,0.90],\n",
    "    horizon_minutes=24*60, # TODO: Find out: Does this influence anything? Does this influence which lagged features are available at prediction time?\n",
    "    resolution_minutes=15,\n",
    "    forecast_type=\"demand\", # Note, this should become optional\n",
    "    lat = 1, # should become optional\n",
    "    lon = 1, # should become optional\n",
    "    # train_components=False, #should become optional\n",
    "    # model_type_group=None, # Note, this should become optional\n",
    "    # hyper_params={}, # Note, this should become optional\n",
    "    # feature_names=None, # Note, this should become optional\n",
    ")\n",
    "\n",
    "# The modelspecs do not do much if only an \"id\" is specified.\n",
    "modelspecs = ModelSpecificationDataClass(id=pj['id'])\n",
    "\n",
    "# Define backtest specs.\n",
    "backtest_specs = dict(n_folds=3, \n",
    "                      # The training horizon also decides for which forecast horizon, backtest forecasts are made.\n",
    "                      training_horizons=[0.25, 47.0, 24.0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c4f3e8d",
   "metadata": {},
   "source": [
    "#### Perform the backtest\n",
    "Perform and save the results of the backtest 10 times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccaffc56",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    # Perform the backtest\n",
    "    forecast, models, train_data, validation_data, test_data = train_model_and_forecast_back_test(\n",
    "        pj,\n",
    "        modelspecs = modelspecs,\n",
    "        input_data = input_data,\n",
    "        **backtest_specs,\n",
    "    )\n",
    "\n",
    "    # Correct forecast and realized for Vattenfall C-ARM measurements and power forecasts\n",
    "    quantile_columns = [col for col in forecast.columns if \"quantile\" in col]\n",
    "\n",
    "\n",
    "    for horizon in set(forecast.horizon):\n",
    "        forecast.loc[forecast.horizon == horizon, \"forecast\"] = (\n",
    "            forecast.query(\"horizon == @horizon\")[\"forecast\"] +\n",
    "            aggregated_vattenfall_power_forecasts\n",
    "        )\n",
    "\n",
    "        forecast.loc[forecast.horizon == horizon, quantile_columns] = (\n",
    "            forecast.query(\"horizon == @horizon\")[quantile_columns].apply(\n",
    "                lambda q_col: q_col + aggregated_vattenfall_power_forecasts\n",
    "            )\n",
    "        )\n",
    "\n",
    "        forecast.loc[forecast.horizon == horizon, \"realised\"] = (\n",
    "            forecast.query(\"horizon == @horizon\")[\"realised\"] +\n",
    "            aggregated_vattenfall_load\n",
    "        )\n",
    "    \n",
    "    # If n_folds > 1, models is a list of models. In that case, only use the first model.\n",
    "    if backtest_specs['n_folds'] > 1:\n",
    "        model=models[0]\n",
    "    else:\n",
    "        model=models\n",
    "    \n",
    "    run_name = f\"{datetime.utcnow():%Y%m%d}_MDM_with_Vattenfall_bottom_up_sample_{i}\"\n",
    "    write_artifacts(run_name, forecast, model, pj, backtest_specs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c1ea4aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option(\"display.max_columns\", 130)\n",
    "train_data[0].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f38725a",
   "metadata": {},
   "source": [
    "# Evaluation of the backtest results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19c92b27",
   "metadata": {},
   "source": [
    "## Boxplots of rMAE, rMSE, and rMAE of the 5 percent lowest values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d75c66b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare results\n",
    "import openstef.metrics.metrics as metrics\n",
    "\n",
    "list_res = []\n",
    "overal_results = {}\n",
    "for sample in range(10):\n",
    "    res_metrics = {}\n",
    "    res_top_down = pd.read_csv(f\"./output/20230720_MDM_top_down_sample_{sample}/forecast.csv\", parse_dates=True, index_col=0, compression='gzip')\n",
    "    res_bottom_up = pd.read_csv(f\"./output/20230720_MDM_with_Vattenfall_bottom_up_sample_{sample}/forecast.csv\", parse_dates=True, index_col=0, compression='gzip')\n",
    "    res_metrics[\"Top_down\"]= [metrics.r_mae_lowest(res_top_down[\"realised\"], res_top_down[\"forecast\"]),\n",
    "                              metrics.r_mae(res_top_down[\"realised\"], res_top_down[\"forecast\"]),\n",
    "                              metrics.rmse(res_top_down[\"realised\"], res_top_down[\"forecast\"])]\n",
    "    res_metrics[\"Vattenfall_forecasts_included\"] = [metrics.r_mae_lowest(res_bottom_up[\"realised\"], res_bottom_up[\"forecast\"]),\n",
    "                                                    metrics.r_mae(res_bottom_up[\"realised\"], res_bottom_up[\"forecast\"]),\n",
    "                                                    metrics.rmse(res_bottom_up[\"realised\"], res_bottom_up[\"forecast\"])]\n",
    "\n",
    "    res_metrics_df = pd.DataFrame.from_dict(res_metrics)\n",
    "    res_metrics_df.index = [\"rMAE_lowest\", \"rMAE\", \"rMSE\"]\n",
    "\n",
    "    overal_results[sample] = res_metrics_df\n",
    "\n",
    "    list_res.append(overal_results[sample])\n",
    "\n",
    "results = pd.concat(list_res).reset_index()\n",
    "\n",
    "fig = results[results[\"index\"]==\"rMSE\"][[\"Vattenfall_forecasts_included\", \"Top_down\"]].plot(title=\"\", kind=\"box\", labels=dict(value=\"rMSE\"))\n",
    "fig.update_layout(yaxis=dict(rangemode='tozero'))\n",
    "fig.show()\n",
    "\n",
    "fig = results[results[\"index\"]==\"rMAE\"][[\"Vattenfall_forecasts_included\", \"Top_down\"]].plot(title=\"\", kind=\"box\", labels=dict(value=\"rMAE\"))\n",
    "fig.update_layout(yaxis=dict(rangemode='tozero'))\n",
    "fig.show()\n",
    "\n",
    "fig = results[results[\"index\"]==\"rMAE_lowest\"][[\"Vattenfall_forecasts_included\", \"Top_down\"]].plot(kind=\"box\",title=\"\", labels=dict(value=\"rMAE_lowest\"))\n",
    "fig.update_layout(yaxis=dict(rangemode='tozero'))\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35616c05",
   "metadata": {},
   "source": [
    "#### Visualize top_down forecasts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65f7f432",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.quantile_plotting import plot_quantile_forecasts_and_realized\n",
    "\n",
    "sample = 0\n",
    "forecasts_top_down = pd.read_csv(f\"./output/20230720_MDM_top_down_sample_{sample}/forecast.csv\", parse_dates=True, index_col=0, compression='gzip')\n",
    "\n",
    "horizon = 24.0\n",
    "\n",
    "plot_quantile_forecasts_and_realized(\n",
    "    realized=forecasts_top_down.query(\"horizon == @horizon\")[\"realised\"],\n",
    "    forecast=forecasts_top_down.query(\"horizon == @horizon\")[\"forecast\"],\n",
    "    quantiles=forecasts_top_down.query(\"horizon == @horizon\")[[q for q in forecasts_top_down.columns if q[:8] == \"quantile\"]],\n",
    "    horizon=horizon,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30af297e",
   "metadata": {},
   "source": [
    "#### Visualize forecasts with Vattenfall included"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76764e8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import quantile_plotting\n",
    "\n",
    "sample = 0\n",
    "forecasts_Vattenfall_included = pd.read_csv(f\"./output/20230720_MDM_with_Vattenfall_bottom_up_sample_{sample}/forecast.csv\", parse_dates=True, index_col=0, compression='gzip')\n",
    "\n",
    "horizon = 24.0\n",
    "\n",
    "plot_quantile_forecasts_and_realized(\n",
    "    realized=forecasts_Vattenfall_included.query(\"horizon == @horizon\")[\"realised\"],\n",
    "    forecast=forecasts_Vattenfall_included.query(\"horizon == @horizon\")[\"forecast\"],\n",
    "    quantiles=forecasts_Vattenfall_included.query(\"horizon == @horizon\")[[q for q in forecasts_Vattenfall_included.columns if q[:8] == \"quantile\"]],\n",
    "    horizon=horizon,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25042869",
   "metadata": {},
   "source": [
    "# Export notebook as html\n",
    "Write this notebook to html."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f731c300",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "nb_fname = '05.Compare_top_down_MDM_to_MDM_with_Vattenfall_1_on_1'\n",
    "run_name = f\"{datetime.utcnow():%Y%m%d}_comparison_top_down_MDM_to_MDM_with_Vattenfall_1_on_1\"\n",
    "command=f\"jupyter nbconvert {nb_fname}.ipynb --to html --no-input --output results/{run_name}.html\"\n",
    "print(f\"Command to be executed: {command}.\")\n",
    "os.system(command)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0431780",
   "metadata": {},
   "source": [
    "# Open points:\n",
    "- What is the horizon of the customer power forecasts?\n",
    "    - The power forecasts are updated about 20-35 times per day. For this analysis, the most recent power forecasts are used. So, we can assume the forecast horizon is about one hour.\n",
    "- Why is the curtailment of the 25th of may not incorporated in the Vattenfall power forecasts?\n",
    "    - This was a request from TenneT to the Alliander operations to switch of the fields of the Vattenfall windpark. There was no request to Vattenfall.\n",
    "- How do the customer power forecasts compare to the OpenSTEF forecasts in terms of quality?\n",
    "- Regarding the 19th of december incident: How long before curtailment, was the curtailment request sent by TenneT?\n",
    "    - The curtailment request was sent in real-time / just in time."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
